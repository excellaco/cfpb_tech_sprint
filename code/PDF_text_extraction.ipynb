{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz # PyMuPDF library, install with pip install pymupdf --> https://github.com/pymupdf/PyMuPDF\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "def PDF_data_extract(pdf_path, image_resolution=300):\n",
    "    \"\"\"\n",
    "    Note -- this is not an OCR module, instead it uses PyMuPDF to extract text and metadata directly from PDF documents.\n",
    "    It utilizes the getTextBlocks function to get \"block\"-level text and image groupings that are extracted by PyMuPDF. \n",
    "    \n",
    "    Data is returned as a pandas dataframe with columns:\n",
    "      - page: page number (starting at 1)\n",
    "      - block: block number for a given page (starting at 1)\n",
    "      - X1: X coordinate of upper left corner of block bounding box\n",
    "      - Y1: Y coordinate of upper left corner of block bounding box\n",
    "      - X2: X coordinate of lower right corner of block bounding box\n",
    "      - Y2: Y coordinate of lower right corner of block bounding box\n",
    "      - text: text contained in block\n",
    "      \n",
    "     Extra columns for tracking document name and extraction method are included.\n",
    "    \n",
    "    If desired, this can be adjusted to get page-level, paragraph-level, line-level and word-level text\n",
    "    groupings.\n",
    "    \n",
    "    For example, to get individual words see here:\n",
    "    https://pymupdf.readthedocs.io/en/latest/functions/#Page.getTextWords\n",
    "    \"\"\"\n",
    "    \n",
    "    # Handle whether or not a document can be opened\n",
    "    try:\n",
    "        \n",
    "        # Open PDF using PyMuPDF library\n",
    "        pdf = fitz.open(pdf_path)\n",
    "        \n",
    "        # Handls whether or not an opened document can be processed\n",
    "        try:\n",
    "\n",
    "            # intialize dictionaries to be used for processing\n",
    "            pdf_pages_dfs = {}\n",
    "\n",
    "            # Iterate through pages of PDF file\n",
    "            for i in range(0, pdf.pageCount):    \n",
    "\n",
    "                # Handle empty pages\n",
    "                try:\n",
    "                    \n",
    "                    # extract text and metadata from page, load into dataframe\n",
    "                    temp_df = pd.DataFrame(pdf.loadPage(i).getTextWords())   # extracts list of individual word/token strings\n",
    "\n",
    "                    # Data cleaning, rearranging, etc...\n",
    "                    temp_df['filename'] = re.split(r'/|\\\\', pdf_path)[-1][:-4]\n",
    "                    temp_df = temp_df.rename(columns = {0:'x1', 1:'y1', 2:'x2', 3:'y2', 4:'text', 5:'block', 6:'line', 7:'word'})\n",
    "                    temp_df['page'] = int(i + 1)\n",
    "                    temp_df['block'] = temp_df['block'] + 1\n",
    "                    temp_df['line'] = temp_df['line'] + 1\n",
    "                    temp_df['word'] = temp_df['word'] + 1\n",
    "                    \n",
    "                    # don't need bounding box coordinates, drop them.  Reorder remaining columns\n",
    "                    temp_df = temp_df[['filename', 'page', 'block', 'line', 'word', 'text']]\n",
    "\n",
    "                    # Save page-level dataframe to PDF-level dictionary, with page keys as integers\n",
    "                    pdf_pages_dfs.update({int(i+1):temp_df}) \n",
    "\n",
    "                except:\n",
    "\n",
    "                    print(\"   ****** Page \" + str(i+1) + \" was empty ******\")\n",
    "                    pass\n",
    "\n",
    "            # Concatenate all page-level dataframes of PDF into a single dataframe\n",
    "            temp_df_list = [v for k, v in pdf_pages_dfs.items()]\n",
    "            pdf_df = pd.concat(temp_df_list, axis=0).reset_index(drop=True)      \n",
    "\n",
    "            print('Successfully extracted data from ' + pdf_path.rsplit('\\\\')[-1])\n",
    "            \n",
    "        except:\n",
    "            print(\"\\n   ****** Cannot process opened pdf ******\\n\")\n",
    "            pdf.close()\n",
    "            return\n",
    "            \n",
    "    except:\n",
    "        print(\"\\n   ****** Cannot open pdf ******\\n\")\n",
    "        return\n",
    "\n",
    "    return pdf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_folder_path = '../data/initial_ideas/'\n",
    "filenames = os.listdir(file_folder_path)\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in filenames:\n",
    "    if file[-4:] == '.pdf':\n",
    "        print(file)\n",
    "        file_path = f\"{file_folder_path}{file}\"\n",
    "        df = PDF_data_extract(file_path, image_resolution=300)\n",
    "        save_path = f\"{file_folder_path}csv_out/{file}\"\n",
    "        df.to_csv(f'{save_path}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr",
   "language": "python",
   "name": "ocr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
